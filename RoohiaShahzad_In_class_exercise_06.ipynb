{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RoohiaShahzad_In_class_exercise_06.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Roohiashahzad/Roohia_INFO5731_Spring2020/blob/main/RoohiaShahzad_In_class_exercise_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7TahL04sVvR"
      },
      "source": [
        "# **The sixth in-class-exercise (20 points in total, 3/2/2021)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejyZITr8sjnh"
      },
      "source": [
        "## **1. Rule-based information extraction (10 points)**\n",
        "\n",
        "Use any keywords related to data science, natural language processing, machine learning to search from google scholar, get the **titles** of 100 articles (either by web scraping or manually) about this topic, define a set of patterns to extract the research questions/problems, methods/algorithms/models, datasets, applications, or any other important information about this topic. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvR_O9D8sOUY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8c9e19a-b51d-4b27-e6e7-ec0f6561e336"
      },
      "source": [
        "# Write your code here\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "pattern1=[]\r\n",
        "pattern2=[]\r\n",
        "pattern3=[]\r\n",
        "df=pd.read_csv(\"/content/MachineLearning100titles.csv\", sep = '\\t', encoding='latin1')\r\n",
        "\r\n",
        "df=df.replace(u'\\xa0', u'0')\r\n",
        "df['Title']=df['Title'].str.replace('\\xa0',' ')\r\n",
        "df\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Machine learning basics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Readings in machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Machine learning: Trends, perspectives, and pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Optimization for machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Encyclopedia of machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Foundations of machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Elements of machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The impact of machine learning on economics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Understanding machine learning: From theory to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Machine learning that matters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>What is machine learning?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Machine-learning research</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Machine learning: the new AI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Genetic algorithms and machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Machine learning and the physical sciences</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Python machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Practical machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Machine learning: a probabilistic perspective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Machine learning and law</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The discipline of machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Machine learning and its applications to biology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Machine learning in agriculture: A review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Pattern recognition and machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Dlib-ml: A machine learning toolkit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Learnware: on the future of machine learning.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Torch7: A matlab-like environment for machine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Machine learning algorithms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Types of machine learning algorithms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>Pylearn2: a machine learning research library</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>An introduction to machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>A brief review of machine learning and its app...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>Machine learning and radiology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>Machine learning: the art and science of algor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>Ensemble methods in machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>A review of studies on machine learning techni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>Ensemble machine learning: methods and applica...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>Mllib: Machine learning in apache spark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>Supervised machine learning: A review of class...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>Real-world machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>Machine learning: a historical and methodologi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>The computational complexity of machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>How the machine 'thinks': Understanding opacit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>(Machine) learning to do more with less</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>Advances in financial machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>A survey of optimization methods from a machin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>Dadiannao: A machine-learning supercomputer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>A review of supervised machine learning algori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>Argument based machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>Machine learning unifies the modeling of mater...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>Machine learning: a Bayesian and optimization ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>Three pitfalls to avoid in machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>Survey of machine learning algorithms for dise...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>Machine learning phases of matter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Machine learning for dummies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Machine learning methods that economists shoul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Pattern recognition and machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Kernel methods in machine learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Practical coreset constructions for machine le...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Title\n",
              "0                                    Machine learning\n",
              "1                             Machine learning basics\n",
              "2                        Readings in machine learning\n",
              "3   Machine learning: Trends, perspectives, and pr...\n",
              "4                   Optimization for machine learning\n",
              "5                    Encyclopedia of machine learning\n",
              "6                     Foundations of machine learning\n",
              "7                                    Machine learning\n",
              "8                        Elements of machine learning\n",
              "9         The impact of machine learning on economics\n",
              "10  Understanding machine learning: From theory to...\n",
              "11                      Machine learning that matters\n",
              "12                          What is machine learning?\n",
              "13                          Machine-learning research\n",
              "14                       Machine learning: the new AI\n",
              "15            Genetic algorithms and machine learning\n",
              "16         Machine learning and the physical sciences\n",
              "17                            Python machine learning\n",
              "18                         Practical machine learning\n",
              "19      Machine learning: a probabilistic perspective\n",
              "20                           Machine learning and law\n",
              "21                 The discipline of machine learning\n",
              "22   Machine learning and its applications to biology\n",
              "23          Machine learning in agriculture: A review\n",
              "24           Pattern recognition and machine learning\n",
              "25                Dlib-ml: A machine learning toolkit\n",
              "26      Learnware: on the future of machine learning.\n",
              "27  Torch7: A matlab-like environment for machine ...\n",
              "28                        Machine learning algorithms\n",
              "29               Types of machine learning algorithms\n",
              "..                                                ...\n",
              "70      Pylearn2: a machine learning research library\n",
              "71                An introduction to machine learning\n",
              "72  A brief review of machine learning and its app...\n",
              "73                     Machine learning and radiology\n",
              "74  Machine learning: the art and science of algor...\n",
              "75               Ensemble methods in machine learning\n",
              "76  A review of studies on machine learning techni...\n",
              "77  Ensemble machine learning: methods and applica...\n",
              "78            Mllib: Machine learning in apache spark\n",
              "79  Supervised machine learning: A review of class...\n",
              "80                        Real-world machine learning\n",
              "81  Machine learning: a historical and methodologi...\n",
              "82   The computational complexity of machine learning\n",
              "83  How the machine 'thinks': Understanding opacit...\n",
              "84            (Machine) learning to do more with less\n",
              "85             Advances in financial machine learning\n",
              "86  A survey of optimization methods from a machin...\n",
              "87        Dadiannao: A machine-learning supercomputer\n",
              "88  A review of supervised machine learning algori...\n",
              "89                    Argument based machine learning\n",
              "90  Machine learning unifies the modeling of mater...\n",
              "91  Machine learning: a Bayesian and optimization ...\n",
              "92        Three pitfalls to avoid in machine learning\n",
              "93  Survey of machine learning algorithms for dise...\n",
              "94                  Machine learning phases of matter\n",
              "95                       Machine learning for dummies\n",
              "96  Machine learning methods that economists shoul...\n",
              "97           Pattern recognition and machine learning\n",
              "98                 Kernel methods in machine learning\n",
              "99  Practical coreset constructions for machine le...\n",
              "\n",
              "[100 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VauShIzXkDJ6",
        "outputId": "2674fffa-5d03-4f51-ec58-7e61fdb57f5a"
      },
      "source": [
        "for t in df['Title']:\r\n",
        "  exp=re.findall(\"^[A-Za-z]+\\s+(?:machine+\\s+learning)$\",t)#Pattern Extraction\r\n",
        "  exp2=re.findall(\"^[A-Za-z]+\\s+[A-Za-z]+\\s+(?:machine+\\s+learning)$\",t)#Pattern Extraction\r\n",
        "  exp3=re.findall(\"(.*):\\s*([^,]+)\",t)#Pattern Extraction\r\n",
        "  exp4=re.findall(\"[^.!?;]*(?:for)[^.!?;]*\",t)#Pattern Extraction\r\n",
        "  if len(exp)!=0 or len(exp2)!=0:\r\n",
        "    pattern1.append(t)\r\n",
        "  elif len(exp3)!=0:\r\n",
        "   pattern2.append(t)\r\n",
        "  elif len(exp4)!=0:\r\n",
        "   pattern3.append(t)\r\n",
        "print(\"Pattern1 :\",pattern1)\r\n",
        "print()\r\n",
        "print(\"Pattern2 :\",pattern2)\r\n",
        "print()\r\n",
        "print(\"Pattern3 :\",pattern3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pattern1 : ['Readings in machine learning', 'Optimization for machine learning', 'Encyclopedia of machine learning', 'Foundations of machine learning', 'Elements of machine learning', 'Python machine learning', 'Practical machine learning', 'Statistics for machine learning', 'Introduction to machine learning', 'MATLAB machine learning', 'Argument based machine learning']\n",
            "\n",
            "Pattern2 : ['Machine learning: Trends, perspectives, and prospects', 'Understanding machine learning: From theory to algorithms', 'Machine learning: the new AI', 'Machine learning: a probabilistic perspective', 'Machine learning in agriculture: A review', 'Dlib-ml: A machine learning toolkit', 'Learnware: on the future of machine learning.', 'Torch7: A matlab-like environment for machine learning', 'Bioinformatics: the machine learning approach', 'Uncovering social spammers: social honeypots+ machine learning', 'Machine learning: an algorithmic perspective', 'Machine learning: A theoretical approach', 'Machine learning algorithms: a review', 'Machine learning: an applied econometric approach', 'The boosting approach to machine learning: An overview', 'Mlaas: Machine learning as a service', 'ModelDB: a system for machine learning model management', 'Machine learning for sequential data: A review', 'Machine learning: algorithms and applications', 'Graphlab: A new framework for parallel machine learning', 'Python Machine Learning: Machine Learning and Deep Learning with Python', 'MoleculeNet: a benchmark for molecular machine learning', 'Machine learning from theory to algorithms: an overview', 'Machine learning: a guide to current research', 'Pylearn2: a machine learning research library', 'Machine learning: the art and science of algorithms that make sense of data', 'Ensemble machine learning: methods and applications', 'Mllib: Machine learning in apache spark', 'Supervised machine learning: A review of classification techniques', 'Machine learning: a historical and methodological analysis', \"How the machine 'thinks': Understanding opacity in machine learning algorithms\", 'Dadiannao: A machine-learning supercomputer', 'Machine learning: a Bayesian and optimization perspective']\n",
            "\n",
            "Pattern3 : ['Machine learning for molecular and materials science', 'Machine learning for fluid mechanics', 'Machine learning in bioinformatics', 'QoT estimation for unestablished lighpaths using machine learning', 'Survey of machine learning algorithms for disease diagnostic', 'Machine learning for dummies', 'Practical coreset constructions for machine learning']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq_7VGmrsum4"
      },
      "source": [
        "## **2. Domain-specific information extraction (10 points)**\n",
        "\n",
        "For the legal case used in the data cleaning exercise: [01-05-1 Adams v Tanner.txt](https://raw.githubusercontent.com/unt-iialab/info5731_spring2021/main/class_exercises/01-05-1%20%20Adams%20v%20Tanner.txt), use [legalNLP](https://lexpredict-lexnlp.readthedocs.io/en/latest/modules/extract/extract.html#nlp-based-extraction-methods) to extract the following inforation from the text (if the information is not exist, just print None):\n",
        "\n",
        "(1) acts, e.g., “section 1 of the Advancing Hope Act, 1986”\n",
        "\n",
        "(2) amounts, e.g., “ten pounds” or “5.8 megawatts”\n",
        "\n",
        "(3) citations, e.g., “10 U.S. 100” or “1998 S. Ct. 1”\n",
        "\n",
        "(4) companies, e.g., “Lexpredict LLC”\n",
        "\n",
        "(5) conditions, e.g., “subject to …” or “unless and until …”\n",
        "\n",
        "(6) constraints, e.g., “no more than”\n",
        "\n",
        "(7) copyright, e.g., “(C) Copyright 2000 Acme”\n",
        "\n",
        "(8) courts, e.g., “Supreme Court of New York”\n",
        "\n",
        "(9) CUSIP, e.g., “392690QT3”\n",
        "\n",
        "(10) dates, e.g., “June 1, 2017” or “2018-01-01”\n",
        "\n",
        "(11) definitions, e.g., “Term shall mean …”\n",
        "\n",
        "(12) distances, e.g., “fifteen miles”\n",
        "\n",
        "(13) durations, e.g., “ten years” or “thirty days”\n",
        "\n",
        "(14) geographic and geopolitical entities, e.g., “New York” or “Norway”\n",
        "\n",
        "(15) money and currency usages, e.g., “$5” or “10 Euro”\n",
        "\n",
        "(16) percents and rates, e.g., “10%” or “50 bps”\n",
        "\n",
        "(17) PII, e.g., “212-212-2121” or “999-999-9999”\n",
        "\n",
        "(18) ratios, e.g.,” 3:1” or “four to three”\n",
        "\n",
        "(19) regulations, e.g., “32 CFR 170”\n",
        "\n",
        "(20) trademarks, e.g., “MyApp (TM)”\n",
        "\n",
        "(21) URLs, e.g., “http://acme.com/”\n",
        "\n",
        "(22) addresses, e.g., “1999 Mount Read Blvd, Rochester, NY, USA, 14615”\n",
        "\n",
        "(23) persons, e.g., “John Doe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnv-sHmfzxMI",
        "outputId": "a2a7e7b0-e754-4f71-cf6d-1f37df0a78ff"
      },
      "source": [
        "f = open(\"/content/01-05-1  Adams v Tanner.txt\",\"r\") \r\n",
        "data = f.read()\r\n",
        "!pip install lexnlp"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lexnlp in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already satisfied: joblib==0.14.0 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.14.0)\n",
            "Requirement already satisfied: scipy==1.5.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (1.5.1)\n",
            "Requirement already satisfied: pandas==0.24.2 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.24.2)\n",
            "Requirement already satisfied: nltk==3.5 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (3.5)\n",
            "Requirement already satisfied: requests==2.24.0 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (2.24.0)\n",
            "Requirement already satisfied: num2words==0.5.10 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.5.10)\n",
            "Requirement already satisfied: pycountry==20.7.3 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (20.7.3)\n",
            "Requirement already satisfied: us==2.0.2 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (2.0.2)\n",
            "Requirement already satisfied: numpy==1.19.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (1.19.1)\n",
            "Requirement already satisfied: Unidecode==1.1.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (1.1.1)\n",
            "Requirement already satisfied: reporters-db==2.0.3 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn==0.23.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.23.1)\n",
            "Requirement already satisfied: dateparser==0.7.2 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.7.2)\n",
            "Requirement already satisfied: regex==2020.7.14 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (2020.7.14)\n",
            "Requirement already satisfied: gensim==3.8.3 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (3.8.3)\n",
            "Requirement already satisfied: datefinder-lexpredict==0.6.2.1 in /usr/local/lib/python3.7/dist-packages (from lexnlp) (0.6.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from pandas==0.24.2->lexnlp) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.7/dist-packages (from pandas==0.24.2->lexnlp) (2018.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->lexnlp) (4.41.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->lexnlp) (7.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (3.0.4)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words==0.5.10->lexnlp) (0.6.2)\n",
            "Requirement already satisfied: jellyfish==0.6.1 in /usr/local/lib/python3.7/dist-packages (from us==2.0.2->lexnlp) (0.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from reporters-db==2.0.3->lexnlp) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.1->lexnlp) (2.1.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser==0.7.2->lexnlp) (1.5.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->lexnlp) (4.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32MFMdAAz_KA",
        "outputId": "4beb3b1e-3d4f-4cba-8cac-609a38541421"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "nltk.download('wordnet')\r\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upfRcWpRz_ha",
        "outputId": "004d67ea-3ff5-49fa-f43e-d847e1f3f5e1"
      },
      "source": [
        "#acts\r\n",
        "import lexnlp.extract.en.acts\r\n",
        "if lexnlp.extract.en.acts.get_act_list(data):\r\n",
        " print(lexnlp.extract.en.acts.get_act_list(data))\r\n",
        "else:\r\n",
        " print('None')\r\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUUqMT_Hz_i7",
        "outputId": "aa3cf63c-9396-4b40-b0d7-7f96add05c81"
      },
      "source": [
        "#amounts\r\n",
        "import lexnlp.extract.en.amounts\r\n",
        "if lexnlp.extract.en.amounts.get_amounts(data):\r\n",
        " print(list(lexnlp.extract.en.amounts.get_amounts(data)))\r\n",
        "else:\r\n",
        " print('None')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Decimal('5.0'), Decimal('740.0'), Decimal('1843.0'), Decimal('2.0'), Decimal('1.0'), Decimal('4.0'), Decimal('2.0'), Decimal('1821.0'), Decimal('5.0'), Decimal('1.0'), Decimal('1840.0'), Decimal('3777.0'), Decimal('80.0'), Decimal('100.0'), Decimal('30.0'), Decimal('1839.0'), Decimal('741.0'), Decimal('22.0'), Decimal('1840.0'), Decimal('14000.0'), Decimal('120.0'), Decimal('1.0'), Decimal('1840.0'), Decimal('3.0'), Decimal('4.0'), Decimal('1.0'), Decimal('1.0'), Decimal('1840.0'), Decimal('2.0'), Decimal('1.0'), Decimal('361.0'), Decimal('1.0'), Decimal('307.0'), Decimal('6.0'), Decimal('604.0'), Decimal('1.0'), Decimal('2.0'), Decimal('418.0'), Decimal('422.0'), Decimal('7.0'), Decimal('34.0'), Decimal('41.0'), Decimal('167.0'), Decimal('742.0'), Decimal('3.0'), Decimal('112.0'), Decimal('207.0'), Decimal('3.0'), Decimal('338.0'), Decimal('424.0'), Decimal('5.0'), Decimal('26.0'), Decimal('13.0'), Decimal('235.0'), Decimal('8.0'), Decimal('693.0'), Decimal('4.0'), Decimal('1821.0'), Decimal('167.0'), Decimal('2.0'), Decimal('2.0'), Decimal('216.0'), Decimal('3.0'), Decimal('66.0'), Decimal('4.0'), Decimal('130.0'), Decimal('29.0'), Decimal('2.0'), Decimal('241.0'), Decimal('2.0'), Decimal('332.0'), Decimal('2.0'), Decimal('422.0'), Decimal('9.0'), Decimal('112.0'), Decimal('743.0'), Decimal('9.0'), Decimal('39.0'), Decimal('14000.0'), Decimal('1840.0'), Decimal('744.0'), Decimal('5.0'), Decimal('182.0'), Decimal('3.0'), Decimal('368.0'), Decimal('1.0'), Decimal('397.0'), Decimal('6.0'), Decimal('604.0'), Decimal('1.0'), Decimal('1821.0'), Decimal('167.0'), Decimal('745.0'), Decimal('4.0'), Decimal('746.0'), Decimal('4.0'), Decimal('210.0'), Decimal('46.0'), Decimal('747.0'), Decimal('5.0'), Decimal('5.0'), Decimal('740.0'), Decimal('1843.0'), Decimal('284.0'), Decimal('2019.0'), Decimal('9.0'), Decimal('1.0'), Decimal('55.0'), Decimal('266.0'), Decimal('271.0'), Decimal('1876.0'), Decimal('2.0'), Decimal('47.0'), Decimal('362.0'), Decimal('376.0'), Decimal('1872.0'), Decimal('3.0'), Decimal('45.0'), Decimal('329.0'), Decimal('334.0'), Decimal('1871.0'), Decimal('4.0'), Decimal('31.0'), Decimal('526.0'), Decimal('527.0'), Decimal('1858.0'), Decimal('5.0'), Decimal('21.0'), Decimal('333.0'), Decimal('335.0'), Decimal('1852.0'), Decimal('6.0'), Decimal('8.0'), Decimal('145.0'), Decimal('147.0'), Decimal('1857.0'), Decimal('7.0'), Decimal('65.0'), Decimal('256.0'), Decimal('258.0'), Decimal('3.0'), Decimal('1880.0'), Decimal('8.0'), Decimal('4.0'), Decimal('913.0'), Decimal('914.0'), Decimal('1887.0'), Decimal('9.0'), Decimal('103.0'), Decimal('464.0'), Decimal('1936.0'), Decimal('3.0'), Decimal('1.0'), Decimal('9.0'), Decimal('39.0'), Decimal('1828.0'), Decimal('2.0'), Decimal('2.0'), Decimal('5.0'), Decimal('182.0'), Decimal('1837.0'), Decimal('2.0'), Decimal('3.0'), Decimal('9.0'), Decimal('108.0'), Decimal('1812.0'), Decimal('6.0'), Decimal('1.0'), Decimal('2.0')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPbXUflL0h33",
        "outputId": "3a71e4b9-79a2-4879-a328-c3b8636f84f2"
      },
      "source": [
        "#citations\r\n",
        "import lexnlp.extract.en.citations\r\n",
        "if lexnlp.extract.en.citations.get_citations(data):\r\n",
        " print(list(lexnlp.extract.en.citations.get_citations(data)))\r\n",
        "else:\r\n",
        " print('None') \r\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(5, 'Ala.', 'Alabama Reports', 740, None, None, None), (5, 'Ala.', 'Alabama Reports', 740, '1843', None, None), (55, 'Ala.', 'Alabama Reports', 266, '271', None, None), (47, 'Ala.', 'Alabama Reports', 362, '376', None, None), (45, 'Ala.', 'Alabama Reports', 329, '334', None, None), (31, 'Ala.', 'Alabama Reports', 526, '527', None, None), (21, 'Ala.', 'Alabama Reports', 333, '335', None, None), (8, 'Cal.', 'California Reports', 145, '147', None, None), (65, 'Ala.', 'Alabama Reports', 256, '258', None, None), (4, 'S.W.', 'South Western Reporter', 913, '914', None, None), (103, 'A.L.R.', 'American Law Reports', 464, None, None, None), (9, 'Cow.', \"Cowen's Reports\", 39, None, None, None), (5, 'Port.', 'Alabama Reports, Porter', 182, None, None, None), (9, 'Johns.', \"Johnson's Reports\", 108, None, None, None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGvNXpTE0h5W",
        "outputId": "b94783cd-fba1-495e-a418-e2dfb650eb45"
      },
      "source": [
        "#companies\r\n",
        "import lexnlp.extract.en.entities.nltk_re\r\n",
        "if lexnlp.extract.en.entities.nltk_re.get_companies(data):\r\n",
        " print(list(lexnlp.extract.en.entities.nltk_re.get_companies(data)))\r\n",
        "else:\r\n",
        " print('None')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Lehman, Durr Co, (17983, 18001)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il5Z2UXp0h9D",
        "outputId": "7e8ee4af-c1ab-4dfa-ef90-615ad37b8b00"
      },
      "source": [
        "#conditions\r\n",
        "import lexnlp.extract.en.conditions\r\n",
        "if lexnlp.extract.en.conditions.get_conditions(data):\r\n",
        " print(list(lexnlp.extract.en.conditions.get_conditions(data)))\r\n",
        "else:\r\n",
        " print('None')\r\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('until', '[2]\\nCreditors’ Remedies\\nLien and Priority\\nUnder St.1821, prohibiting a levy on a crop', ''), ('until', 'on a growing crop, nor does such lien attach', ''), ('if', 'It was proved by the claimants, by the production of a written contract, that Harrison, on the twenty-second of May, 1840, in consideration that the claimants were involved, as indorsers for Burton & Harrison of Sumter county, and were then exposed to an execution, amounting to upwards of fourteen thousand dollars, bargained and sold to the claimants all his growing crop of cotton &c., consisting of one hundred and twenty acres, &c. Allen Harrison promised and obliged himself to give up his crop to the use of the claimants at any time to save them from suffering as his indorsers;', ''), ('when', 'The claimants came from Tennessee, (where they resided) about the first of September, 1840, bringing with them three or four white laborers, and took possession of the crop and slaves, and with the latter, and white laborers, gathered the cotton, prepared it for market, and', ''), ('if', 'The court charged the jury, that the plaintiff had no lien by virtue of his judgment, and execution on the growing crop; that Harrison had a right to convey it, without being in any manner restrained by them; that the writing adduced, was a sale of the crop, but', ''), ('when', 'it was not, and the lien of the fieri facias would have attached upon it,', ''), ('if', 'gathered, yet', ''), ('not subject to', 'the claimants obtained possession on the first of September, and controlled the gathering of the crop, then no lien attached, and it was', ''), ('until', 'Rep, 693;] and', ''), ('until', '167,] which declares it to be lawful to levy an execution on a planted crop,', ''), ('if', 'It is admitted that the contract between the defendant in execution, and the claimants, was in good faith,', ''), ('when', 'The defendant in execution might at any time have divested the interest which the contract vested in the claimants, by discharging their liability as his indorsers, or a judgment creditor might have satisfied the lien, and', ''), ('unless', 'We will then consider the writing under which the claimants assert a right, as a mortgage with a power to take possession any time during the year,', ''), ('if', 'Conceding the truth of the facts stated in the bill of exceptions, and we think it will not follow, that the possession of the claimants is a nullity, and that the case must be considered as', ''), ('if', 'The contract contains an express undertaking to give up the crop at any time the claimants might require it for their indemnity, and', ''), ('if', 'they took possession of it in the absence of the grantor, (though without his consent,)', ''), ('if', 'he subsequently acquiesced in it, the inference would be,', ''), ('subject to', 'Mr. Dane, in remarking upon this point, says, “The American editor of Bacon’s Abridgment, says, ‘Wheat growing in the ground is a chattel, and', ''), ('until', 'The first section of the act of 1821, “To prevent sheriffs and other officers from levying executions in certain cases, enacts, that “It shall not be lawful for any sheriff or other officer, to levy a writ of fieri facias or other execution on the planted crop of a debtor, or person against whom an execution may issue,', ''), ('until', 'Now here is an express inhibition to levy an execution on a crop while it remains on, or in the ground, and', ''), ('until', 'If so, the act cited, will only have the effect of keeping the right to levy it in abeyance', ''), ('if', 'The lien and the right to levy are intimately connected, and', ''), ('until', 'That it was competent for the legislature to have made it unlawful to levy an execution on particular property,', ''), ('until', 'If the object was merely to suspend the sale,', ''), ('as soon as', 'The idea that the lien attached upon the planted crop', ''), ('until', 'the execution was delivered to the sheriff, though the right to levy it was postponed', ''), ('if', 'They do not refer to the lien,', ''), ('until', 'they did they would postpone it', ''), ('until', 'the crop was gathered; but it is the levy they relate to and postpone', ''), ('until', '**4 The right to levy an execution on a planted crop, then, being expressly taken away by the statute, the lien which is connected with and consequent upon that right, never attaches', ''), ('if', 'The circuit judge may have mistaken the law in supposing that the contract was a sale, but', ''), ('when', 'There is no assumption of any material fact in the charge; but the possession of the claimant, the time', ''), ('if', 'acquired, the gathering of the crop, &c., are all referred to the determination of the jury; who are instructed,', ''), ('until', '**4 The statute which presents the question before the court is, that “it shall not be lawful for any sheriff or other officer to levy a writ of fieei facias or other execution, on the planted crop of a debtor, or person against whom an execution may issue,', ''), ('subject to', 'The policy of the State, as indicated by these statutes, is undeniably that all the property of a debtor, real and personal, to which he has a legal title, shall be', ''), ('until', 'The mischief which the statute designed to remedy was, the sacrifice which would be necessarily made by the sale of an immature crop: the statute enables the debtor to retain it', ''), ('if', '**5', ''), ('until', 'The sheriff is forbidden to levy on a “planted crop”', ''), ('if', 'Now,', ''), ('until', 'This, I feel a thorough conviction, was not the intention of the legislature; but that it was to secure him from loss, by prohibiting a levy and sale of the crop,', ''), ('when', 'it was gathered,', ''), ('subject to', 'Growing crops as', ''), ('subject to', '464\\nGenerally, at common law, growing crops raised by annual planting, while still attached to the soil, are regarded as personal chattels,', ''), ('where', 'And', '')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmWyj9EK0h-o",
        "outputId": "bbfc0800-7b42-41a8-ac61-596725c05533"
      },
      "source": [
        "#constraints\r\n",
        "import lexnlp.extract.en.constraints\r\n",
        "if lexnlp.extract.en.constraints.get_constraints(data):\r\n",
        " print(list(lexnlp.extract.en.constraints.get_constraints(data)))\r\n",
        "else:\r\n",
        " print('None')\r\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('after', 'on a growing crop, nor does such lien attach until', ''), ('after', '', ' and that alias and pluries fieri facias’, issued regularly up to the time levy was made; that the cotton levied on was growed on the plantation of harrison, and cultivated by the hands in his service.'), ('first of', 'the claimants came from tennessee, (where they resided) about the', ''), ('first of', 'the court charged the jury, that the plaintiff had no lien by virtue of his judgment, and execution on the growing crop; that harrison had a right to convey it, without being in any manner restrained by them; that the writing adduced, was a sale of the crop, but if it was not, and the lien of the fieri facias would have attached upon it, when gathered, yet if the claimants obtained possession on the', ''), ('after', 'it merely inhibits the levy, but the lien attaches, and a levy and sale may be made', ''), ('more than', 'taking this to be clear *744 law, and it will be seen, that the defendant in execution at the time of the levy had nothing', ''), ('before', 'it has been frequently mooted whether, at common law, corn, &c.,', ''), ('before', '**4 the statute which presents the question', ''), ('after', 'now, if the view taken by the majority of the court, is correct, the right secured to the plaintiff in execution, of levying on the crop', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', ''), ('before', 'tried', '')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIu6U5lI0iEl",
        "outputId": "f39263f9-53b9-40ad-e510-8e14d5322e63"
      },
      "source": [
        "#copyright\r\n",
        "import lexnlp.extract.en.copyright\r\n",
        "if lexnlp.extract.en.copyright.get_copyright(data):\r\n",
        " print(list(lexnlp.extract.en.copyright.get_copyright(data)))\r\n",
        "else:\r\n",
        " print('None')\r\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('©', '2019', 'Thomson Reuters. No')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "slaXGezI0vCO",
        "outputId": "3a3071cd-3f69-49b7-87b7-3a6882f2ba79"
      },
      "source": [
        "#courts \r\n",
        "#https://raw.githubusercontent.com/LexPredict/lexpredict-legal-dictionary/1.0.5/en/legal/us_courts.csv\r\n",
        "import pandas\r\n",
        "import lexnlp.extract.en.courts\r\n",
        "\r\n",
        "court_df = pandas.read_csv(\"https://raw.githubusercontent.com/LexPredict/lexpredict-legal-dictionary/master/en/legal/us_courts.csv\")\r\n",
        "court_config_data = []\r\n",
        "for _, row in court_df.iterrows():\r\n",
        " c = lexnlp.extract.en.dict_entities.entity_config(row[\"Court ID\"], row[\"Court Name\"], 0, row[\"Alias\"].split(\";\") if not pandas.isnull(row[\"Alias\"]) else []).court_config_data.append(c)\r\n",
        "for entity, alias in lexnlp.extract.en.courts.get_courts(data, court_config_data):\r\n",
        " print(\"entity=\", entity)\r\n",
        " print(\"alias=\", alias)\r\n"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-159-23f2bdcca6bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcourt_config_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcourt_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m  \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlexnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict_entities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Court ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Court Name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Alias\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Alias\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcourt_config_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malias\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlexnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcourts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_courts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcourt_config_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m  \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"entity=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'lexnlp.extract.en.dict_entities' has no attribute 'entity_config'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlNJwcc00vDs",
        "outputId": "780ec4bf-ec76-45bc-8411-f7dcea4ff34f"
      },
      "source": [
        "#CUSIP\r\n",
        "import lexnlp.extract.en.cusip\r\n",
        "if lexnlp.extract.en.cusip.get_cusip_list(data):\r\n",
        " print(lexnlp.extract.en.cusip.get_cusip_list(data))\r\n",
        "else:\r\n",
        " print('None')\r\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBH_eZyM0vIG",
        "outputId": "2a07dc42-f952-490f-a615-8bac1925776d"
      },
      "source": [
        "#dates\r\n",
        "import lexnlp.extract.en.dates\r\n",
        "if lexnlp.extract.en.dates.get_dates(data):\r\n",
        " print(list(lexnlp.extract.en.dates.get_dates(data)))\r\n",
        "else:\r\n",
        " print('None')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[datetime.date(2021, 6, 1), datetime.date(1840, 11, 1), datetime.date(1839, 10, 1), datetime.date(1840, 9, 1), datetime.date(1840, 5, 1), datetime.date(1840, 5, 1), datetime.date(2021, 12, 1), datetime.date(2021, 12, 1), datetime.date(2021, 1, 1), datetime.date(2021, 1, 1), datetime.date(2021, 1, 1), datetime.date(2021, 3, 21), datetime.date(2021, 6, 1), datetime.date(2021, 7, 1), datetime.date(2021, 11, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnKZNQmd0vjO",
        "outputId": "d6bc66ca-2c1e-45c7-8556-19736bda6e33"
      },
      "source": [
        "#definitions\r\n",
        "import lexnlp.extract.en.definitions\r\n",
        "if list(lexnlp.extract.en.definitions.get_definitions(data)):\r\n",
        " print(list(lexnlp.extract.en.definitions.get_definitions(data)))\r\n",
        "else:\r\n",
        " print('None')\r\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gUnFF920iGG",
        "outputId": "887c2b0f-1179-489d-f3fc-057e8d54e59b"
      },
      "source": [
        "#distances\r\n",
        "import lexnlp.extract.en.distances\r\n",
        "if list(lexnlp.extract.en.distances.get_distances(data)):\r\n",
        " print(list(lexnlp.extract.en.distances.get_distances(data)))\r\n",
        "else:\r\n",
        " print('None')\r\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-9jQsSa5niK",
        "outputId": "b8899a6d-ed7d-49c2-bec0-c8c11966d8a4"
      },
      "source": [
        "#durations\r\n",
        "import lexnlp.extract.en.durations\r\n",
        "if list(lexnlp.extract.en.durations.get_durations(data)):\r\n",
        " print(list(lexnlp.extract.en.durations.get_durations(data)))\r\n",
        "else:\r\n",
        " print('None')\r\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('second', Decimal('20.0'), Decimal('0.0002')), ('year', Decimal('6.0'), Decimal('2190.0'))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvcyVKbK5nkD",
        "outputId": "f9d86bdc-0b44-4561-8a75-8bed47fc68a3"
      },
      "source": [
        "#geographic and geopolitical entities,\r\n",
        "from lexnlp.extract.common.base_path import lexnlp_test_path\r\n",
        "from lexnlp.extract.en.dict_entities import prepare_alias_banlist_dict, AliasBanRecord\r\n",
        "from lexnlp.extract.en.geoentities import get_geoentities, load_entities_dict_by_path\r\n",
        "#from lexnlp.tests import lexnlp_tests \r\n",
        "import os\r\n",
        "#def load_entities_dict():\r\n",
        " # base_path = os.path.join(lexnlp_test_path, 'https://raw.githubusercontent.com/LexPredict/lexpredict-legal-dictionary/master/en/legal/us_courts.csv')\r\n",
        "  #entities_fn = os.path.join(base_path, 'geoentities.csv')\r\n",
        "  #aliases_fn = os.path.join(base_path, 'geoaliases.csv')\r\n",
        "  #return load_entities_dict_by_path(entities_fn, aliases_fn)\r\n",
        "#_CONFIG = list(load_entities_dict())\r\n",
        "#court_config_data is the list used while extracting the data of courts above\r\n",
        "if list(get_geoentities(data,geo_config_list=court_config_data)):\r\n",
        " print(list(get_geoentities(data,geo_config_list=court_config_data)))\r\n",
        "else:\r\n",
        " print('None')"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjMkcLJc5nnq",
        "outputId": "23d6fb4b-aaa5-4dcb-c849-e71bf8d067df"
      },
      "source": [
        "#money and currency usages\r\n",
        "import lexnlp.extract.en.money\r\n",
        "if list(lexnlp.extract.en.money.get_money(data)):\r\n",
        " print(list(lexnlp.extract.en.money.get_money(data)))\r\n",
        "else:\r\n",
        " print('None')\r\n"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(Decimal('100.0'), 'USD'), (Decimal('14000.0'), 'USD'), (Decimal('14000.0'), 'USD')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hppb3qgJ6AO9",
        "outputId": "b1b2e5e2-86b4-4c6d-a8ab-0d4c17a2bd33"
      },
      "source": [
        "#percentage and rates\r\n",
        "import lexnlp.extract.en.percents\r\n",
        "if list(lexnlp.extract.en.percents.get_percents(data)):\r\n",
        " print(list(lexnlp.extract.en.percents.get_percents(data)))\r\n",
        "else:\r\n",
        " print('None')\r\n"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvlRwKR36AQc",
        "outputId": "8d61ec5d-c9c3-416f-f217-992c8e3aa0b9"
      },
      "source": [
        "#pii\r\n",
        "import lexnlp.extract.en.pii\r\n",
        "if list(lexnlp.extract.en.pii.get_pii(data)):\r\n",
        " print(list(lexnlp.extract.en.pii.get_pii(data)))\r\n",
        "else:\r\n",
        " print('None')\r\n"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dzvajXU6AT9",
        "outputId": "e90a4e8f-c25a-48d4-f26b-0541d820ef97"
      },
      "source": [
        "#ratios\r\n",
        "import lexnlp.extract.en.ratios\r\n",
        "if list(lexnlp.extract.en.ratios.get_ratios(data)):\r\n",
        " print((list(lexnlp.extract.en.ratios.get_ratios(data))))\r\n",
        "else:\r\n",
        " print('None')\r\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppR-tyCr6AVS",
        "outputId": "5aa1ebf4-075f-4ae8-ca96-a1f28b639e44"
      },
      "source": [
        "#regulations\r\n",
        "import lexnlp.extract.en.regulations\r\n",
        "if list(lexnlp.extract.en.regulations.get_regulations(data)):\r\n",
        " print(list(lexnlp.extract.en.regulations.get_regulations(text)))\r\n",
        "else:\r\n",
        " print('None')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xoeb1zj6Jlk",
        "outputId": "61b45668-0e0f-4432-b259-fb493d2eeb67"
      },
      "source": [
        "#trademarks\r\n",
        "import lexnlp.extract.en.trademarks\r\n",
        "if list(lexnlp.extract.en.trademarks.get_trademarks(data)):\r\n",
        " print(list(lexnlp.extract.en.trademarks.get_trademarks(text)))\r\n",
        "else:\r\n",
        " print('None')\r\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whgdldq76Jvx",
        "outputId": "3016c3bb-87ba-487d-a2fd-60cfe5a410b2"
      },
      "source": [
        "#UrLs\r\n",
        "import lexnlp.extract.en.urls\r\n",
        "if list(lexnlp.extract.en.urls.get_urls(data)):\r\n",
        " print(list(lexnlp.extract.en.urls.get_urls(data)))\r\n",
        "else:\r\n",
        " print('None')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "dhr2myz26J0D",
        "outputId": "77e35337-f3d9-4c70-d756-d1ec73913565"
      },
      "source": [
        "#addresses\r\n",
        "import lexnlp.extract.en.addresses\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "word_tokens = word_tokenize(data)\r\n",
        "if list(lexnlp.extract.en.addresses.get_addresses(data)):\r\n",
        "  print(list(lexnlp.extract.en.addresses.get_addresses(data)))\r\n",
        "else:\r\n",
        "  print('None')\r\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-62b002d36aa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mword_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddresses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_addresses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddresses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_addresses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'lexnlp.extract.en.addresses' has no attribute 'get_addresses'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AASWYdR-6SYf",
        "outputId": "18e7527a-a4a6-493b-932c-4026bfcf5a2a"
      },
      "source": [
        "!pip install pyap"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyap in /usr/local/lib/python3.7/dist-packages (0.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iuk_VTAq6J1f",
        "outputId": "e39c8a25-936b-4ad9-d007-12b461dadb36"
      },
      "source": [
        "import pyap\r\n",
        "addresses = pyap.parse(data, country='US')\r\n",
        "adrs = []\r\n",
        "for address in addresses:\r\n",
        " adrs.append(address)\r\n",
        "print(adrs)\r\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C531C1ye6AjN",
        "outputId": "f7cc6074-9af5-4c7d-b312-279358f93a0c"
      },
      "source": [
        "from nltk.tag.stanford import StanfordNERTagger\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "import nltk\r\n",
        "!wget 'https://nlp.stanford.edu/software/stanford-ner-2018-10-16.zip'\r\n",
        "!unzip stanford-ner-2018-10-16.zip\r\n",
        "1nltk.download('punkt')\r\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-07 04:21:05--  https://nlp.stanford.edu/software/stanford-ner-2018-10-16.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180358328 (172M) [application/zip]\n",
            "Saving to: ‘stanford-ner-2018-10-16.zip.1’\n",
            "\n",
            "stanford-ner-2018-1 100%[===================>] 172.00M  6.05MB/s    in 38s     \n",
            "\n",
            "2021-03-07 04:21:43 (4.57 MB/s) - ‘stanford-ner-2018-10-16.zip.1’ saved [180358328/180358328]\n",
            "\n",
            "Archive:  stanford-ner-2018-10-16.zip\n",
            "replace stanford-ner-2018-10-16/README.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/README.txt  \n",
            "replace stanford-ner-2018-10-16/ner-gui.bat? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/ner-gui.bat  \n",
            "replace stanford-ner-2018-10-16/build.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/build.xml  \n",
            "replace stanford-ner-2018-10-16/stanford-ner.jar? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/stanford-ner.jar  \n",
            "replace stanford-ner-2018-10-16/sample-conll-file.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/sample-conll-file.txt  \n",
            "replace stanford-ner-2018-10-16/sample.ner.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/sample.ner.txt  \n",
            "replace stanford-ner-2018-10-16/stanford-ner-3.9.2-sources.jar? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/stanford-ner-3.9.2-sources.jar  \n",
            "replace stanford-ner-2018-10-16/lib/joda-time.jar? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/lib/joda-time.jar  \n",
            "replace stanford-ner-2018-10-16/lib/stanford-ner-resources.jar? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/lib/stanford-ner-resources.jar  \n",
            "replace stanford-ner-2018-10-16/lib/jollyday-0.4.9.jar? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/lib/jollyday-0.4.9.jar  \n",
            "replace stanford-ner-2018-10-16/ner-gui.command? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/ner-gui.command  \n",
            "replace stanford-ner-2018-10-16/ner.sh? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/ner.sh  \n",
            "replace stanford-ner-2018-10-16/stanford-ner-3.9.2.jar? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/stanford-ner-3.9.2.jar  \n",
            "replace stanford-ner-2018-10-16/NERDemo.java? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/NERDemo.java  \n",
            "replace stanford-ner-2018-10-16/stanford-ner-3.9.2-javadoc.jar? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/stanford-ner-3.9.2-javadoc.jar  \n",
            "replace stanford-ner-2018-10-16/ner.bat? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/ner.bat  \n",
            "replace stanford-ner-2018-10-16/classifiers/english.conll.4class.distsim.prop? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.conll.4class.distsim.prop  \n",
            "replace stanford-ner-2018-10-16/classifiers/example.serialized.ncc.ncc.ser.gz? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/classifiers/example.serialized.ncc.ncc.ser.gz  \n",
            "replace stanford-ner-2018-10-16/classifiers/english.muc.7class.distsim.crf.ser.gz? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.muc.7class.distsim.crf.ser.gz  \n",
            "replace stanford-ner-2018-10-16/classifiers/english.conll.4class.distsim.crf.ser.gz? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.conll.4class.distsim.crf.ser.gz  \n",
            "replace stanford-ner-2018-10-16/classifiers/english.muc.7class.distsim.prop? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.muc.7class.distsim.prop  \n",
            "replace stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.prop? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.prop  \n",
            "replace stanford-ner-2018-10-16/classifiers/example.serialized.ncc.prop? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/classifiers/example.serialized.ncc.prop  \n",
            "replace stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.crf.ser.gz? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.crf.ser.gz  \n",
            "replace stanford-ner-2018-10-16/sample.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/sample.txt  \n",
            "replace stanford-ner-2018-10-16/sample-w-time.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/sample-w-time.txt  \n",
            "replace stanford-ner-2018-10-16/ner-gui.sh? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/ner-gui.sh  \n",
            "replace stanford-ner-2018-10-16/LICENSE.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: stanford-ner-2018-10-16/LICENSE.txt  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCr9EgTs6Akx"
      },
      "source": [
        "st = StanfordNERTagger('/content/stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.crf.ser.gz','/content/stanford-ner-2018-10-16/stanford-ner.jar',\r\n",
        " encoding='utf-8')\r\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asUVX2HM6zU-",
        "outputId": "58ae0024-b19b-4c41-8878-45e6a1949725"
      },
      "source": [
        "#persons\r\n",
        "classified_text = st.tag(word_tokens)\r\n",
        "for x,y in classified_text:\r\n",
        " if y == 'PERSON':\r\n",
        "   print(x)\r\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ADAMS\n",
            "TANNER\n",
            "HORTON\n",
            "Lien\n",
            "Allen\n",
            "Harrison\n",
            "Allen\n",
            "Harrison\n",
            "Harrison\n",
            "Harrison\n",
            "Allen\n",
            "Harrison\n",
            "Harrison\n",
            "Harrison\n",
            "R.\n",
            "H.\n",
            "SMITH\n",
            "Harrison\n",
            "Salk\n",
            "Harrison\n",
            "Johns\n",
            "Harrison\n",
            "W.\n",
            "M.\n",
            "MURPHY\n",
            "W.\n",
            "G.\n",
            "JONES\n",
            "Johns\n",
            "C.\n",
            "J\n",
            "Chas\n",
            "Whipple\n",
            "Johns\n",
            "Stewart\n",
            "Doughty\n",
            "Johns\n",
            "Sawyer\n",
            "Perkins\n",
            "Elliott\n",
            "Mayfield\n",
            "Dane\n",
            "Whipple\n",
            "Poole\n",
            "Salk\n",
            "Whipple\n",
            "Mansony\n",
            "Hurtell\n",
            "Wood\n",
            "Gary\n",
            "Booker\n",
            "Jones\n",
            "M.\n",
            "J.\n",
            "SAFFOLD\n",
            "Marshall\n",
            "Montgomery\n",
            "Hon\n",
            "JOHN\n",
            "D.\n",
            "CUNNINGHAM\n",
            "Bibb\n",
            "Janney\n",
            "Hon\n",
            "JOHN\n",
            "D.\n",
            "CUNNINGHAM\n",
            "McKenzie\n",
            "Lampley\n",
            "S.\n",
            "D.\n",
            "HALE\n",
            "Evans\n",
            "Lamar\n",
            "B.\n",
            "MOORE\n",
            "Dewey\n",
            "Bowman\n",
            "Jacob\n",
            "S.\n",
            "Cohen\n",
            "Cohen\n",
            "Rees\n",
            "L.\n",
            "WHITLOCK\n",
            "Edwards\n",
            "Thompson\n",
            "Weakley\n",
            "Austin\n",
            "Sawyer\n",
            "Perkins\n",
            "Mayfield\n",
            "Stewart\n",
            "Johns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K78hHGpo6zWq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}