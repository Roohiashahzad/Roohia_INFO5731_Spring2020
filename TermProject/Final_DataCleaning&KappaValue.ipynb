{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_DataCleaning&KappaValue.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75vM2Vn14z5u"
      },
      "source": [
        "#Reading Data files and Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "9eWps20D-oYa",
        "outputId": "67c1d314-03a2-4547-d62a-bc91d6069dc6"
      },
      "source": [
        "import pandas as pd\n",
        "filename = \"/content/Jassist_PM_ACL - Annotation.csv\" #anotated file\n",
        "data = pd.read_csv(filename, encoding= 'unicode_escape')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Articles</th>\n",
              "      <th>Contributions</th>\n",
              "      <th>Source</th>\n",
              "      <th>Annotation1</th>\n",
              "      <th>Annotation2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Text Mining for Personalized Knowledge Extract...</td>\n",
              "      <td>Extend and evaluate existing textâmining tec...</td>\n",
              "      <td>JASIST</td>\n",
              "      <td>Algorithm or Method or Technology Optimization</td>\n",
              "      <td>Algorithm or Method or Technology Optimization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Text Mining for Personalized Knowledge Extract...</td>\n",
              "      <td>Design and develop a layer for extraction of k...</td>\n",
              "      <td>JASIST</td>\n",
              "      <td>New Algorithm or Method or Technology</td>\n",
              "      <td>New Algorithm or Method or Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Text Mining for Personalized Knowledge Extract...</td>\n",
              "      <td>Evaluate relevance, reliability, and demonstra...</td>\n",
              "      <td>JASIST</td>\n",
              "      <td>Performance Evaluation</td>\n",
              "      <td>Performance Evaluation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PSI: A probabilistic semantic interpretable fr...</td>\n",
              "      <td>A novel semantic interpretable framework is pr...</td>\n",
              "      <td>JASIST</td>\n",
              "      <td>Theory Proposal</td>\n",
              "      <td>Model Construction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PSI: A probabilistic semantic interpretable fr...</td>\n",
              "      <td>with the attribute based representation and su...</td>\n",
              "      <td>JASIST</td>\n",
              "      <td>Algorithm or Method or Technology Optimization</td>\n",
              "      <td>Algorithm or Method or Technology Optimization</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Articles  ...                                     Annotation2\n",
              "0  Text Mining for Personalized Knowledge Extract...  ...  Algorithm or Method or Technology Optimization\n",
              "1  Text Mining for Personalized Knowledge Extract...  ...           New Algorithm or Method or Technology\n",
              "2  Text Mining for Personalized Knowledge Extract...  ...                          Performance Evaluation\n",
              "3  PSI: A probabilistic semantic interpretable fr...  ...                              Model Construction\n",
              "4  PSI: A probabilistic semantic interpretable fr...  ...  Algorithm or Method or Technology Optimization\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1HpJX8aDxvr"
      },
      "source": [
        "data['lower_Case'] = data['Contributions'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Siwg1h1DxxN"
      },
      "source": [
        "data['remove_Punc'] = data['lower_Case'].str.replace('[^\\w\\s]','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQLTVBfjDxzw",
        "outputId": "9a923972-008b-4a7a-c090-e531cd0422f0"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "data['stop_words'] = data['remove_Punc'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neDK5Pp4Dx1T"
      },
      "source": [
        "frequent_words = list(pd.Series(' '.join(data['Contributions']).split()).value_counts()[:15].index)\n",
        "data[\"freq_words\"] = data['stop_words'].apply(lambda x: ' '.join([i for i in x.split() if i not in frequent_words]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbDg3ZweDx_N"
      },
      "source": [
        "from textblob import TextBlob\n",
        "data['word_tokenize'] = data['freq_words'].apply(lambda x: TextBlob(x).words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0NNcc1hDyAv",
        "outputId": "edb2ca0f-45b7-487a-c7ea-aa8eefc642b4"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from textblob import Word\n",
        "data['lemmatized'] = data['word_tokenize'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFKv6dXxDyDW"
      },
      "source": [
        "cleaned_data = data[['lemmatized', 'Annotation1', 'Annotation2']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRVpz0GaDyE9"
      },
      "source": [
        "cleaned_data.to_csv('/content/cleaned_data.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHmF6zbY4wu4"
      },
      "source": [
        "#Kappa Value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2QD2uhIE4km",
        "outputId": "03128a19-7ec6-4691-d511-5d39fad3f5a4"
      },
      "source": [
        "from sklearn import metrics\n",
        "kappa_value = metrics.cohen_kappa_score(cleaned_data['Annotation1'], cleaned_data['Annotation2'])\n",
        "print('Kappa value is {0}'.format(kappa_value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kappa value is 0.7991692024090605\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}